{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "11C5lyBEiNRRcN1mEiNZt1GuoDJKslKLZ",
      "authorship_tag": "ABX9TyMtgKUJ4oYedRTxYBJohKCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ramesh8/ner-train-google-colab/blob/main/learningd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKbHhjTFKfyl"
      },
      "outputs": [],
      "source": [
        "print(\"hello world\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "learning deep learning :)"
      ],
      "metadata": {
        "id": "HhsNMMuNLIdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6p6NO6OLNjW",
        "outputId": "08ccdb09-e013-4399-919a-83e26cf2094a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5HNGPjRhs2g",
        "outputId": "5aa99d4f-0c54-4f1e-b2f4-8a5d59da635d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade spacy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZEjT7OAh-gy",
        "outputId": "c3b0eae3-0820-4f1b-a97d-91e3da9fd160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Collecting spacy\n",
            "  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "Installing collected packages: spacy\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 3.5.2\n",
            "    Uninstalling spacy-3.5.2:\n",
            "      Successfully uninstalled spacy-3.5.2\n",
            "Successfully installed spacy-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U 'spacy[cuda-autodetect]'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9Wksl3jY8pf",
        "outputId": "dc313456-6fcc-43be-e476-bdf00823847c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy[cuda-autodetect] in /usr/local/lib/python3.10/dist-packages (3.5.2)\n",
            "Collecting spacy[cuda-autodetect]\n",
            "  Downloading spacy-3.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[cuda-autodetect]) (3.3.0)\n",
            "Collecting cupy-wheel<13.0.0,>=11.0.0 (from spacy[cuda-autodetect])\n",
            "  Downloading cupy-wheel-12.1.0.tar.gz (3.1 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cupy-cuda11x==12.1.0 (from cupy-wheel<13.0.0,>=11.0.0->spacy[cuda-autodetect])\n",
            "  Downloading cupy_cuda11x-12.1.0-cp310-cp310-manylinux2014_x86_64.whl (89.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x==12.1.0->cupy-wheel<13.0.0,>=11.0.0->spacy[cuda-autodetect]) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy[cuda-autodetect]) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda-autodetect]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda-autodetect]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda-autodetect]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda-autodetect]) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[cuda-autodetect]) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[cuda-autodetect]) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy[cuda-autodetect]) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy[cuda-autodetect]) (2.1.2)\n",
            "Building wheels for collected packages: cupy-wheel\n",
            "  Building wheel for cupy-wheel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cupy-wheel: filename=cupy_wheel-12.1.0-0_cupy-cuda11x-py3-none-any.whl size=1012 sha256=c2944f821322953798df9f06e9ce9ecf480977d03d5e433567d83bdc288a3b87\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/a2/9e/645c817f394e55a0ccce142142d5f6a946fd14e351b97116d8\n",
            "\u001b[33m  WARNING: Built wheel for cupy-wheel is invalid: cupy_wheel-12.1.0-0_cupy-cuda11x-py3-none-any.whl is not a valid wheel filename.\u001b[0m\u001b[33m\n",
            "\u001b[0mFailed to build cupy-wheel\n",
            "\u001b[31mERROR: Could not build wheels for cupy-wheel, which is required to install pyproject.toml-based projects\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2Hv7uayNerw",
        "outputId": "5351729f-2333-4774-8949-15688310ef7f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ1yrmWnjP1i",
        "outputId": "8c31523d-9585-4ce3-f6a6-85d87d22531e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0.tar.gz\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.5.0/en_core_web_lg-3.5.0.tar.gz (587.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-lg==3.5.0) (2.1.2)\n",
            "Building wheels for collected packages: en-core-web-lg\n",
            "  Building wheel for en-core-web-lg (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-lg: filename=en_core_web_lg-3.5.0-py3-none-any.whl size=587689446 sha256=36f750c39561ce8c5a75f37dc3ff7aeeac9ccf68c7bd5dbfba61aa8f6969ed7b\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/5f/83/070c602171eeb2a7e910587270101cf9a5deda23c539a9511d\n",
            "Successfully built en-core-web-lg\n",
            "Installing collected packages: en-core-web-lg\n",
            "Successfully installed en-core-web-lg-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "gpu = spacy.prefer_gpu()\n",
        "print(gpu)\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(\"This is Ramesh\")\n",
        "\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbk4MXEciUqI",
        "outputId": "f1faa8e2-ce2d-492d-f0cd-32ab729578a9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcL1sZLHYe7o",
        "outputId": "7c922fec-91fe-4b61-9f14-15ef114cbd98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2022 NVIDIA Corporation\n",
            "Built on Wed_Sep_21_10:33:58_PDT_2022\n",
            "Cuda compilation tools, release 11.8, V11.8.89\n",
            "Build cuda_11.8.r11.8/compiler.31833905_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LewBvzbEj7tW",
        "outputId": "753bc767-06d5-486e-bd9c-ea0d89fe27ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSI_X3.4-1968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "iE_lSBXzkCLr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/drive\")"
      ],
      "metadata": {
        "id": "D_TpytuPohVq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "211d36e7-da51-4aca-8960-a9dd24423476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "json_data = []\n",
        "with zipfile.ZipFile(\"/drive/My Drive/ML/NLP/NER/entities.zip\", \"r\") as z:\n",
        "  for fname in z.namelist():\n",
        "    print(fname)\n",
        "    with z.open(fname) as f:\n",
        "      data = f.read()\n",
        "      json_data = json.loads(data.decode(\"utf-8\"))\n",
        "      print(f\"{len(json_data)} entities found\" )\n",
        "\n",
        "for i, group in enumerate(grouper(json_data, split_size)):\n",
        "    with open(f'splits\\entities_split_{i}.json', 'w') as opfile:\n",
        "        groupft = [gi for gi in list(group) if gi]        \n",
        "        json.dump(groupft, opfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgCuf45Nkup2",
        "outputId": "1b8e7972-bb7e-4ba9-d9a5-b501520f36f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entities.json\n",
            "57896 entities found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from itertools import zip_longest\n",
        "\n",
        "split_size = 500\n",
        "\n",
        "def grouper(iterable, n, fillvalue=None):\n",
        "    args = [iter(iterable)] * n\n",
        "    return zip_longest(fillvalue=fillvalue, *args)"
      ],
      "metadata": {
        "id": "jsMVYhccZtB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import zipfile\n",
        "\n",
        "json_data = []\n",
        "with zipfile.ZipFile(\"/drive/My Drive/ML/NLP/NER/entities.zip\", \"r\") as z:\n",
        "  for fname in z.namelist():\n",
        "    print(fname)\n",
        "    with z.open(fname) as f:\n",
        "      data = f.read()\n",
        "      json_data = json.loads(data.decode(\"utf-8\"))\n",
        "      print(f\"{len(json_data)} entities found\" )\n",
        "\n",
        "for i, group in enumerate(grouper(json_data, split_size)):\n",
        "    with open(f'/drive/My Drive/ML/NLP/NER/splits/entities_split_{i}.json', 'w') as opfile:\n",
        "        groupft = [gi for gi in list(group) if gi]        \n",
        "        json.dump(groupft, opfile)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eWaQxNqcyZ9",
        "outputId": "ec24ca9e-54f6-486a-b166-3bdb1d09e2d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entities.json\n",
            "57896 entities found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy convert \"/content/drive/MyDrive/ML/NLP/NER/splits/\" \"/content/drive/MyDrive/ML/NLP/NER/spacy/\" "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7stlL2fnDjF",
        "outputId": "6657fc3b-9e63-42e0-be7a-487f6f63b7a1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 09:10:16.039956: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-05 09:10:17.043136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-05 09:10:18.349085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 09:10:18.349553: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 09:10:18.349720: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 74, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1130, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 778, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 216, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1657, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1404, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 760, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 683, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/convert.py\", line 77, in convert_cli\n",
            "    convert(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/convert.py\", line 142, in convert\n",
            "    db = DocBin(docs=docs, store_user_data=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/tokens/_serialize.py\", line 87, in __init__\n",
            "    for doc in docs:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/converters/json_to_docs.py\", line 16, in json_to_docs\n",
            "    for json_para in json_to_annotations(json_doc):\n",
            "  File \"spacy/training/gold_io.pyx\", line 85, in json_to_annotations\n",
            "KeyError: 'paragraphs'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y1c9wdROnwGo",
        "outputId": "ee69b3cc-56c6-46ed-f579-c1feda24afc0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorrt in /usr/local/lib/python3.10/dist-packages (8.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "splitpath = \"/drive/My Drive/ML/NLP/NER/splits/\"\n",
        "for file in os.listdir(splitpath):\n",
        "  jsonfile = os.path.join(splitpath, file)\n",
        "  targetfile = os.path.splitext(jsonfile)[0]+\".spacy\"\n",
        "  print(jsonfile, targetfile)"
      ],
      "metadata": {
        "id": "3QPdyDVOgKld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import DocBin\n",
        "import json\n",
        "import time\n",
        "import string\n",
        "\n",
        "class trainer:\n",
        "    def __init__(self,tdurl='data\\entities.json',spacy_file='train.spacy'):\n",
        "        self.file_url = tdurl\n",
        "        self.training_data_json = []\n",
        "        self.training_data = []\n",
        "        self.spacy_file_name = spacy_file\n",
        "        self.success_counter = 0\n",
        "        self.fail_counter = 0\n",
        "\n",
        "    def load_training_data(self):\n",
        "        try:\n",
        "            with open(self.file_url,mode='r',encoding='utf-8') as f:\n",
        "                self.training_data_json = json.load(f)\n",
        "                return True\n",
        "        except Exception as ex:\n",
        "            print(\"Failed to Load Trianing Data\")\n",
        "            return False\n",
        "\n",
        "    def prepare_training_data(self):\n",
        "        self.failed_list = []\n",
        "        if len(self.training_data_json)==0:\n",
        "            print(\"No Training Data\")\n",
        "            return False\n",
        "        self.training_data = []\n",
        "        noentscnt = 0\n",
        "        dupscnt = 0\n",
        "        for tdj in self.training_data_json:\n",
        "            _, pid, text,entities = tdj.values()\n",
        "            if len(entities)==0:\n",
        "                noentscnt += 1\n",
        "                continue\n",
        "            for i, ent in enumerate(entities):\n",
        "                if ent[0] == ent[1]:\n",
        "                    del entities[i]\n",
        "            if len(entities)==0:\n",
        "                noentscnt += 1\n",
        "                continue\n",
        "\n",
        "            ent = [tuple(en) for en in entities]\n",
        "            old_len = len(ent)\n",
        "            ent = list(set(ent))\n",
        "            new_len = len(ent)\n",
        "            self.training_data.append((text, {\"entities\":ent}))\n",
        "            if old_len != new_len:\n",
        "                dupscnt += (old_len-new_len)    \n",
        "\n",
        "    def convert_to_spacy_old(self):\n",
        "        self.fail_to_convert_list = []        \n",
        "        invalidChars = set(string.punctuation.replace(\"_\", \" \"))\n",
        "        nlp = spacy.load(\"en_core_web_lg\")\n",
        "        # nlp = spacy.blank(\"en\")\n",
        "        db = DocBin()    \n",
        "        skipped = 0\n",
        "        total = 0\n",
        "        for text, annotations in self.training_data:\n",
        "            doc = nlp.make_doc(text)\n",
        "            ents = []\n",
        "            \n",
        "            for start, end, label in annotations['entities']:\n",
        "                substr = text[start:end]\n",
        "                span = doc.char_span(start, end, label=label, alignment_mode=\"expand\")\n",
        "                total += 1\n",
        "                if span is None:\n",
        "                    skipped += 1\n",
        "                elif span.text.startswith(' ') or span.text.endswith(' '):\n",
        "                    skipped += 1\n",
        "                else:\n",
        "                    ents.append(span)            \n",
        "            _ents = list(set(ents))\n",
        "            try:    \n",
        "                doc.ents = _ents\n",
        "                db.add(doc)   \n",
        "                self.success_counter += 1             \n",
        "            except Exception as ex:\n",
        "                self.fail_counter += 1\n",
        "            \n",
        "        db.to_disk(self.spacy_file_name)\n",
        "        print(self.success_counter, self.fail_counter)\n"
      ],
      "metadata": {
        "id": "Blv1-F_l2EK7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "splitpath = \"/content/drive/MyDrive/ML/NLP/NER/splits/\"\n",
        "for file in os.listdir(splitpath):\n",
        "  jsonfile = os.path.join(splitpath, file)\n",
        "  targetfile = os.path.splitext(jsonfile)[0]+\".spacy\"\n",
        "  targetfile = targetfile.replace(\"splits\",\"spacy\")\n",
        "  tr = trainer(jsonfile,targetfile) \n",
        "  tr.load_training_data()\n",
        "  tr.prepare_training_data()\n",
        "  tr.convert_to_spacy_old()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STeiQsDu2IFM",
        "outputId": "4592eeb6-6f14-4940-84e8-0f16c9f7de75"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "344 153\n",
            "337 144\n",
            "312 159\n",
            "385 104\n",
            "360 137\n",
            "395 98\n",
            "375 122\n",
            "313 179\n",
            "257 232\n",
            "310 189\n",
            "316 184\n",
            "348 150\n",
            "297 202\n",
            "330 169\n",
            "326 171\n",
            "313 186\n",
            "325 173\n",
            "327 172\n",
            "337 163\n",
            "307 193\n",
            "342 140\n",
            "248 173\n",
            "289 146\n",
            "293 140\n",
            "291 132\n",
            "226 176\n",
            "195 207\n",
            "248 120\n",
            "278 129\n",
            "235 147\n",
            "260 128\n",
            "255 163\n",
            "287 135\n",
            "262 142\n",
            "270 123\n",
            "277 114\n",
            "193 196\n",
            "237 179\n",
            "262 128\n",
            "217 151\n",
            "250 174\n",
            "268 129\n",
            "251 184\n",
            "199 144\n",
            "219 151\n",
            "180 150\n",
            "259 91\n",
            "178 155\n",
            "182 137\n",
            "409 91\n",
            "400 94\n",
            "317 166\n",
            "375 125\n",
            "385 115\n",
            "412 88\n",
            "440 56\n",
            "451 47\n",
            "442 58\n",
            "459 40\n",
            "424 76\n",
            "456 44\n",
            "452 48\n",
            "425 74\n",
            "437 63\n",
            "446 52\n",
            "443 57\n",
            "461 39\n",
            "454 44\n",
            "466 34\n",
            "427 73\n",
            "403 96\n",
            "452 45\n",
            "430 70\n",
            "384 113\n",
            "425 73\n",
            "400 99\n",
            "402 98\n",
            "420 80\n",
            "397 102\n",
            "415 82\n",
            "407 91\n",
            "358 138\n",
            "389 108\n",
            "426 73\n",
            "422 78\n",
            "437 63\n",
            "376 118\n",
            "381 119\n",
            "402 94\n",
            "376 124\n",
            "435 64\n",
            "387 112\n",
            "365 135\n",
            "328 165\n",
            "334 166\n",
            "384 114\n",
            "388 111\n",
            "369 128\n",
            "437 63\n",
            "434 64\n",
            "402 94\n",
            "361 139\n",
            "429 70\n",
            "379 120\n",
            "401 84\n",
            "379 103\n",
            "381 119\n",
            "372 124\n",
            "386 111\n",
            "412 88\n",
            "432 68\n",
            "422 71\n",
            "433 59\n",
            "458 41\n",
            "369 131\n",
            "283 113\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n",
            "Failed to Load Trianing Data\n",
            "No Training Data\n",
            "0 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMgjil339qGS",
        "outputId": "ff1a90fb-35e1-47d3-c67c-bb874c1bf570"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd drive/MyDrive/ML/NLP/NER/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1zLselb90ze",
        "outputId": "017f68de-8405-4704-a325-c265bd9c0c64"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/ML/NLP/NER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy init fill-config base_config.cfg config.cfg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImUZWi-h-u-2",
        "outputId": "6058a4c6-ffd5-4406-d284-d8c8cdeb0f3c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 10:05:09.225133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-05 10:05:10.296299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-05 10:05:11.662492: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 10:05:11.662899: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 10:05:11.663064: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[38;5;2m✔ Auto-filled config with all values\u001b[0m\n",
            "\u001b[38;5;2m✔ Saved config\u001b[0m\n",
            "config.cfg\n",
            "You can now add your data and train your pipeline:\n",
            "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[sentencepiece]"
      ],
      "metadata": {
        "id": "ULua0dXnAE3_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_trf"
      ],
      "metadata": {
        "id": "mjAqA5NTA2O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train --paths.dev ./dev --gpu-id=0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uoxx3mjOBZUr",
        "outputId": "88b72f5f-3b77-4c17-82b6-7ff583d6a02c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 10:08:55.903692: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-05 10:08:56.954452: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-05 10:08:58.279156: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 10:08:58.279613: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 10:08:58.279792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using GPU: 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-06-05 10:09:04,457] [INFO] Set up nlp object from config\n",
            "[2023-06-05 10:09:04,483] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2023-06-05 10:09:04,489] [INFO] Created vocabulary\n",
            "[2023-06-05 10:09:04,492] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-06-05 10:10:55,368] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (820 > 512). Running this sequence through the model will result in indexing errors\n",
            "\u001b[38;5;3m⚠ Aborting and saving the final best model. Encountered exception:\n",
            "OutOfMemoryError('CUDA out of memory. Tried to allocate 218.00 MiB (GPU 0; 14.75\n",
            "GiB total capacity; 11.49 GiB already allocated; 124.81 MiB free; 13.53 GiB\n",
            "reserved in total by PyTorch) If reserved memory is >> allocated memory try\n",
            "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory\n",
            "Management and PYTORCH_CUDA_ALLOC_CONF')\u001b[0m\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/__main__.py\", line 4, in <module>\n",
            "    setup_cli()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/_util.py\", line 74, in setup_cli\n",
            "    command(prog_name=COMMAND)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1130, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 778, in main\n",
            "    return _main(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/core.py\", line 216, in _main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1657, in invoke\n",
            "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1404, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 760, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/typer/main.py\", line 683, in wrapper\n",
            "    return callback(**use_params)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/train.py\", line 45, in train_cli\n",
            "    train(config_path, output_path, use_gpu=use_gpu, overrides=overrides)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/cli/train.py\", line 75, in train\n",
            "    train_nlp(nlp, output_path, use_gpu=use_gpu, stdout=sys.stdout, stderr=sys.stderr)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/loop.py\", line 124, in train\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/loop.py\", line 107, in train\n",
            "    for batch, info, is_best_checkpoint in training_step_iterator:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/loop.py\", line 232, in train_while_improving\n",
            "    score, other_scores = evaluate()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/training/loop.py\", line 287, in evaluate\n",
            "    scores = nlp.evaluate(dev_corpus(nlp))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 1415, in evaluate\n",
            "    for eg, doc in zip(examples, docs):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/language.py\", line 1574, in pipe\n",
            "    for doc in docs:\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 1670, in _pipe\n",
            "    yield from proc.pipe(docs, **kwargs)\n",
            "  File \"spacy/pipeline/transition_parser.pyx\", line 233, in pipe\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 1617, in minibatch\n",
            "    batch = list(itertools.islice(items, int(batch_size)))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy/util.py\", line 1670, in _pipe\n",
            "    yield from proc.pipe(docs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy_transformers/pipeline_component.py\", line 212, in pipe\n",
            "    self.set_annotations(subbatch, self.predict(subbatch))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy_transformers/pipeline_component.py\", line 229, in predict\n",
            "    activations = self.model.predict(docs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 315, in predict\n",
            "    return self._func(self, X, is_train=False)[0]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/spacy_transformers/layers/transformer_model.py\", line 199, in forward\n",
            "    model_output, bp_tensors = transformer(wordpieces, is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/model.py\", line 291, in __call__\n",
            "    return self._func(self, X, is_train=is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/layers/pytorchwrapper.py\", line 219, in forward\n",
            "    Ytorch, torch_backprop = model.shims[0](Xtorch, is_train)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py\", line 92, in __call__\n",
            "    return self.predict(inputs), lambda a: ...\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/thinc/shims/pytorch.py\", line 110, in predict\n",
            "    outputs = self._model(*inputs.args, **inputs.kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 852, in forward\n",
            "    encoder_outputs = self.encoder(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 527, in forward\n",
            "    layer_outputs = layer_module(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 411, in forward\n",
            "    self_attention_outputs = self.attention(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 338, in forward\n",
            "    self_outputs = self.self(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/roberta/modeling_roberta.py\", line 258, in forward\n",
            "    attention_scores = attention_scores / math.sqrt(self.attention_head_size)\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 218.00 MiB (GPU 0; 14.75 GiB total capacity; 11.49 GiB already allocated; 124.81 MiB free; 13.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy train config.cfg --output ./output --paths.train ./train --paths.dev ./dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8NHvs4DqDhQz",
        "outputId": "63e4f3dd-2e28-4c8f-c758-35180f532c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-05 10:15:51.530644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-05 10:15:53.511410: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-06-05 10:15:56.809158: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 10:15:56.809713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-06-05 10:15:56.809970: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "\u001b[38;5;4mℹ Saving to output directory: output\u001b[0m\n",
            "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
            "\u001b[38;5;4mℹ To switch to GPU 0, use the option: --gpu-id 0\u001b[0m\n",
            "\u001b[1m\n",
            "=========================== Initializing pipeline ===========================\u001b[0m\n",
            "[2023-06-05 10:16:03,617] [INFO] Set up nlp object from config\n",
            "[2023-06-05 10:16:03,633] [INFO] Pipeline: ['transformer', 'ner']\n",
            "[2023-06-05 10:16:03,636] [INFO] Created vocabulary\n",
            "[2023-06-05 10:16:03,638] [INFO] Finished initializing nlp object\n",
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[2023-06-05 10:17:45,039] [INFO] Initialized pipeline components: ['transformer', 'ner']\n",
            "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
            "\u001b[1m\n",
            "============================= Training pipeline =============================\u001b[0m\n",
            "\u001b[38;5;4mℹ Pipeline: ['transformer', 'ner']\u001b[0m\n",
            "\u001b[38;5;4mℹ Initial learn rate: 0.0\u001b[0m\n",
            "E    #       LOSS TRANS...  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
            "---  ------  -------------  --------  ------  ------  ------  ------\n"
          ]
        }
      ]
    }
  ]
}